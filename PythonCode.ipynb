{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code with face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from base64 import b64decode, b64encode\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "from statistics import mean\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional  import InterpolationMode\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from datetime import datetime\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class liveClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(liveClassifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # Conv output = [(256+2x1-3)\\1] + 1 = 256\n",
    "        # Max pooling = (256\\2) = 128\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2))\n",
    "        # Conv output = [(128+2x0-3)\\1] + 1 = 126\n",
    "        # Max pooling = (126\\2) = 63\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2))\n",
    "        # Conv output = [(63+2x0-3)\\1] + 1 = 61\n",
    "        # Max pooling = (61\\2) = 30\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2))\n",
    "        # Conv output = [(30+2x0-3)\\1] + 1 = 28\n",
    "        # Max pooling = (28\\2) = 14\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 1024)\n",
    "        self.drop = nn.Dropout2d(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.drop = nn.Dropout2d(0.5)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 3)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = liveClassifier()\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\agran\\OneDrive - Holon Institute of Technology\\3. Year 3\\Semecter B\\מבוא לתוכנה משובצת מחשב\\Python_Code_face_regoc\\best_model_checkpoint_1.pt'))  # Load your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 8 cm\n",
      "Distance: 54 cm\n",
      "Distance: 55 cm\n",
      "Distance: 12 cm\n",
      "Distance: 5 cm\n",
      "Average Distance: 26.8 cm\n",
      "Distance: 6 cm\n",
      "Average Distance: 26.4 cm\n",
      "Distance: 5 cm\n",
      "Average Distance: 16.6 cm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: 1\n",
      "Distance: 5 cm\n",
      "Average Distance: 6.6 cm\n",
      "Sent: 1\n",
      "Distance: 54 cm\n",
      "Average Distance: 15.0 cm\n",
      "Sent: 1\n",
      "Distance: 54 cm\n",
      "Average Distance: 24.8 cm\n",
      "Sent: 1\n",
      "Distance: 155 cm\n",
      "Average Distance: 54.6 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 64.4 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 74.2 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 74.4 cm\n",
      "Distance: 155 cm\n",
      "Average Distance: 94.6 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 74.6 cm\n",
      "Distance: 155 cm\n",
      "Average Distance: 94.8 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 95.0 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 94.8 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 74.6 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 74.4 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 54.2 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 54.2 cm\n",
      "Distance: 155 cm\n",
      "Average Distance: 74.4 cm\n",
      "Distance: 155 cm\n",
      "Average Distance: 94.6 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 94.6 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 94.8 cm\n",
      "Distance: 55 cm\n",
      "Average Distance: 94.8 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 74.6 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 54.4 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 54.4 cm\n",
      "Distance: 54 cm\n",
      "Average Distance: 54.2 cm\n",
      "Object not within 50 cm for 10 seconds. Pausing inference.\n",
      "Distance: 54 cm\n",
      "Average Distance: 54.0 cm\n",
      "Object not within 50 cm for 10 seconds. Pausing inference.\n",
      "Distance: 55 cm\n",
      "Average Distance: 54.2 cm\n",
      "Object not within 50 cm for 10 seconds. Pausing inference.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import serial\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Open the serial port (replace 'COM5' with the correct port for your system)\n",
    "ser = serial.Serial('COM5', 9600)\n",
    "time.sleep(2)  # Wait for the serial connection to initialize\n",
    "\n",
    "# Define the transform for the video frames\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define class names (adjust based on your dataset)\n",
    "class_names = ['Sahar', 'Yahel', 'Others']\n",
    "\n",
    "# Initialize video capture (0 for webcam or provide video file path)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object to save the video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Settings for distance checking\n",
    "threshold_distance = 50  # cm\n",
    "consecutive_readings_required = 3  # Number of consecutive valid readings below the threshold\n",
    "buffer_size = 5  # Size of the buffer for the moving average\n",
    "\n",
    "# Initialize variables for distance checking\n",
    "distance_buffer = deque(maxlen=buffer_size)\n",
    "below_threshold_counter = 0\n",
    "timeout_start = None\n",
    "timeout_duration = 10  # seconds\n",
    "\n",
    "while True:\n",
    "    # Check distance from Arduino sensor\n",
    "    line = ser.readline().decode('utf-8').strip()\n",
    "    try:\n",
    "        # Extract the distance from the line\n",
    "        if line.startswith(\"Distance:\"):\n",
    "            parts = line.split(\",\")\n",
    "            for part in parts:\n",
    "                if \"Distance\" in part:\n",
    "                    distance = int(part.split(\":\")[1].strip().replace(\"cm\", \"\"))\n",
    "\n",
    "                    # Print the distance\n",
    "                    print(\"Distance:\", distance, \"cm\")\n",
    "\n",
    "                    # Update the distance buffer\n",
    "                    distance_buffer.append(distance)\n",
    "\n",
    "                    # Calculate the moving average distance\n",
    "                    if len(distance_buffer) == buffer_size:\n",
    "                        avg_distance = sum(distance_buffer) / buffer_size\n",
    "                        print(\"Average Distance:\", avg_distance, \"cm\")\n",
    "\n",
    "                        # Check if the average distance is below the threshold\n",
    "                        if avg_distance < threshold_distance:\n",
    "                            below_threshold_counter += 1\n",
    "                            if below_threshold_counter >= consecutive_readings_required:\n",
    "                                timeout_start = None  # Reset timeout if object is within 50 cm\n",
    "                                if not cap.isOpened():\n",
    "                                    cap.open(0)\n",
    "\n",
    "                                ret, frame = cap.read()\n",
    "                                if not ret:\n",
    "                                    break\n",
    "\n",
    "                                frame = cv2.flip(frame, 1)\n",
    "\n",
    "                                # Preprocess the frame\n",
    "                                img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                                img = cv2.resize(img, (256, 256))\n",
    "                                img = transform(img).unsqueeze(0)\n",
    "\n",
    "                                with torch.no_grad():\n",
    "                                    outputs = model(img)\n",
    "                                    probabilities = F.softmax(outputs, dim=1)\n",
    "                                    confidence, predicted = torch.max(probabilities, 1)\n",
    "                                    pred_class_name = class_names[predicted.item()]\n",
    "                                    pred_confidence = confidence.item()\n",
    "\n",
    "                                # Plot classification result on the frame\n",
    "                                x, y = 50, 50  # Position to display the text\n",
    "                                bbox_array = cv2.putText(frame, f\"{pred_class_name}: {pred_confidence:.2f}\", (x, y),\n",
    "                                                         cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255, 0), 1)\n",
    "                                bbox_array_1 = cv2.putText(frame, \"Press 'q' to Exit\", (400, 50),\n",
    "                                                           cv2.FONT_HERSHEY_TRIPLEX, 0.6, (255, 255, 255, 0), 1)\n",
    "\n",
    "                                # Send signal to Arduino based on the classification and confidence\n",
    "                                if pred_class_name in ['Yahel']:\n",
    "                                    ser.write(b'1')\n",
    "                                    print(\"Sent: 1\")\n",
    "                                else:\n",
    "                                    ser.write(b'0')\n",
    "                                    print(\"Sent: 0\")\n",
    "\n",
    "                                # Display the frame\n",
    "                                cv2.imshow('Frame', frame)\n",
    "\n",
    "                                # Write the frame with the classification to the output video\n",
    "                                out.write(frame)\n",
    "\n",
    "                                # Break the loop on 'q' key press\n",
    "                                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                                    break\n",
    "\n",
    "                        else:\n",
    "                            below_threshold_counter = 0\n",
    "                            if timeout_start is None:\n",
    "                                timeout_start = time.time()  # Start timeout if object moves out of 50 cm\n",
    "\n",
    "                            if timeout_start and time.time() - timeout_start >= timeout_duration:\n",
    "                                print(\"Object not within 50 cm for 10 seconds. Pausing inference.\")\n",
    "                                if cap.isOpened():\n",
    "                                    cap.release()\n",
    "                                out.release()\n",
    "                                cv2.destroyAllWindows()\n",
    "                                time.sleep(1)  # Avoid busy waiting\n",
    "                                continue\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Received:\", line)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "if cap.isOpened():\n",
    "    cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Close the serial port\n",
    "ser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
